{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameter sweep for VAE model\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ab3644e823c748d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# torch for data loading and for model building\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# Data preprocessing\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import nibabel as nib\n",
    "\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from PIL import Image\n",
    "from pylab import rcParams\n",
    "\n",
    "# Maths\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "# Other\n",
    "from time import perf_counter\n",
    "from collections import Counter,OrderedDict\n",
    "import random\n",
    "import warnings\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "# import functions from other files\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from models.VAE_2D_model import VAE_2D\n",
    "from utils.datasets import LoadImages, prepare_VAE_MLP_joint_data\n",
    "from utils.utility_code import plot_results, parameter_count, get_single_scan_file_list, weights_init\n",
    "from utils.train_and_test_functions import train, test, train_VAE_model, evaluate_VAE\n",
    "from utils.loss_functions import loss_function, kl_annealing\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define sweep configuration\n",
    "sweep_configuration = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"name\": \"sweep2\",\n",
    "    \"metric\": {\"goal\": \"maximize\", \"name\": \"Test SSIM\"},\n",
    "    \"parameters\": {\n",
    "        \"base\": {\"values\": [16, 20, 24, 28]}, # number of feature maps in convolutional layers\n",
    "        \"latent_size\": {\"values\": [16, 20, 24, 28]}, # size of latent space\n",
    "        \"annealing\": {\"values\": [1]}, # annealing on KL Divergence indicator (0 for NO or 1 for YES)\n",
    "        \"ssim_indicator\": {\"values\": [1]}, # SSIM indicator for loss function: 0 to not inlcude, 1 to include\n",
    "        \"alpha\": {\"values\": [0.4, 0.5, 0.6]}, # If using SSIM/other metric in loss function this is the balance between reconstruction loss (L1/MAE) and the other metric in alpha*L1_loss + (1-alpha)*ssim\n",
    "        \"beta\": {\"values\": [1]}, # multiplier for KL divergence, helps to disentangle latent space. Idea from beta-VAE: https://openreview.net/pdf?id=Sy2fzU9gl\n",
    "        \"lr\": {\"max\": 1e-3, \"min\": 1e-5}, # learning rate (smaller number for slower training)\n",
    "        \"batch_size\": {\"values\": [512, 1024, 1280, 1536]}, # batch size (bigger for more stable training)\n",
    "        \"ssim_scalar\": {\"values\": [0, 0.5, 1, 2, 3]}, # upweight SSIM by this x batch_size\n",
    "        \"recon_scale_factor\": {\"values\": [2500, 3000, 4000, 4500]}, # scale factor for reconstruction loss\n",
    "        \"weight_decay\": {\"max\": 0.06, \"min\": 1e-4}, # weight decay\n",
    "        \"accumulation_steps\": {\"values\": [2, 3, 4]}, # accumulation steps\n",
    "    },\n",
    "}\n",
    "\n",
    "# Initialize sweep by passing in config.\n",
    "# Provide a name of the project.\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"VAE_bayesian_sweep2\")\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7a86e03d8ffce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Run = 0\n",
    "def main():\n",
    "    global Run\n",
    "    IMAGE_DIR = r\"C:\\Users\\mm17b2k.DS\\Documents\\ARCANE_Data\\Cohort1_2D_slices\"\n",
    "    results_path = r\"C:\\Users\\mm17b2k.DS\\Documents\\Python\\ARCANE_Results\"\n",
    "\n",
    "    run = wandb.init()\n",
    "\n",
    "    Run += 1\n",
    "    print(\"Run:\", Run)\n",
    "\n",
    "    save_results_path = rf\"C:\\Users\\mm17b2k.DS\\Documents\\Python\\ARCANE_Results\\VAE_{Run}.pt\"\n",
    "\n",
    "    # Check if GPU available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('Using device:', device)\n",
    "\n",
    "\n",
    "    # settings for reproducibility\n",
    "    torch.manual_seed(int(time.time()))\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    time_start = perf_counter()\n",
    "\n",
    "    all_files_list = ['\\mri' + '//' + f for f in os.listdir(IMAGE_DIR + '\\mri')] + ['\\mri_aug' + '//' + f  for f in os.listdir(IMAGE_DIR + '\\mri_aug')]\n",
    "    all_files_list.sort()\n",
    "\n",
    "\n",
    "    epochs = 200\n",
    "\n",
    "\n",
    "    ssim_list, loss_list = [], []\n",
    "\n",
    "    base = wandb.config.base\n",
    "    latent_size = wandb.config.latent_size\n",
    "    annealing = wandb.config.annealing\n",
    "    ssim_indicator = wandb.config.ssim_indicator\n",
    "    alpha = wandb.config.alpha\n",
    "    beta = wandb.config.beta\n",
    "    lr = wandb.config.lr\n",
    "    batch_size = wandb.config.batch_size\n",
    "    ssim_scalar = wandb.config.ssim_scalar\n",
    "    recon_scale_factor = wandb.config.recon_scale_factor\n",
    "    weight_decay = wandb.config.weight_decay\n",
    "    accumulation_steps = wandb.config.accumulation_steps\n",
    "\n",
    "    hyperparams = {'base': base, 'latent_size': latent_size, 'annealing': annealing, 'ssim_indicator': ssim_indicator, 'alpha': alpha, 'beta': beta, 'lr': lr, 'batch_size': batch_size, 'ssim_scalar': ssim_scalar, 'recon_scale_factor': recon_scale_factor, 'weight_decay': weight_decay, 'accumulation_steps': accumulation_steps}\n",
    "    print(\"Using Hyperparams:\", hyperparams)\n",
    "    print(\"latent size:\", latent_size*base)\n",
    "\n",
    "    patient_files_list = [f for f in os.listdir(IMAGE_DIR + '\\mri')] + [f  for f in os.listdir(IMAGE_DIR + '\\mri_aug')]\n",
    "    patient_ids = []\n",
    "    for file in patient_files_list:\n",
    "        if file[0:21] not in patient_ids:\n",
    "            patient_ids.append(file[0:21])\n",
    "\n",
    "    patient_slices_dict, patient_labels_dict, patient_file_names_dict, short_long_axes_dict, mlp_train_ids, test_ids, mlp_train_labels, test_labels, train_images, test_images, train_test_split_dict, mask_sizes_dict = prepare_VAE_MLP_joint_data(first_time_train_test_split=True, test_proportion=0.35)\n",
    "\n",
    "\n",
    "    train_dataset = LoadImages(main_dir=IMAGE_DIR + '/', files_list=train_images)\n",
    "    test_dataset = LoadImages(main_dir=IMAGE_DIR + '/', files_list=test_images)\n",
    "    train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "\n",
    "    vae_model = VAE_2D(hyperparams)\n",
    "    vae_model = vae_model.to(device)\n",
    "    print('parameter count:', parameter_count(VAE_2D(hyperparams)))\n",
    "    vae_model.apply(weights_init)\n",
    "\n",
    "\n",
    "    vae_model, test_loss, test_ssim, train_loss, train_ssim, VAE_metrics = train_VAE_model(vae_model, epochs, train_loader, test_loader, hyperparams, device, results_path, save_results_path, sample_shape = (12, latent_size*base, 1, 1), train_test_split_dict = train_test_split_dict, wandb_sweep=True, Run=Run)\n",
    "\n",
    "    # if test_ssim > 0.72:\n",
    "    #     plot_results(results_path, save_results_path, 'loss_graph_{}.jpg'.format(Run))\n",
    "    ssim_list.append(test_ssim)\n",
    "    loss_list.append(test_loss)\n",
    "\n",
    "\n",
    "\n",
    "    #idx = loss_list.index(min(loss_list))\n",
    "    print('Hyperparameters:', hyperparams)\n",
    "    cohort1 = pd.read_excel(r\"C:\\Users\\mm17b2k.DS\\Documents\\ARCANE_Data\\Cohort1.xlsx\")\n",
    "\n",
    "    # only one scan per patient to avoid repeated scans\n",
    "    all_files_list2 = get_single_scan_file_list(all_files_list, IMAGE_DIR, cohort1)\n",
    "    all_files_list2.sort()\n",
    "    VAE_metrics, mus = evaluate_VAE(vae_model, test_loss, results_path, batch_size, device, IMAGE_DIR,\n",
    "                                    all_files_list2, feature_length=latent_size*base, Run=Run, wandb_sweep=True)\n",
    "\n",
    "    print(\"Time to train:\", perf_counter() - time_start)\n",
    "    print(f\"Cooling down for 5 mins...\")\n",
    "    time.sleep(300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad12315a324726b",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Start sweep job.\n",
    "wandb.agent(sweep_id, function=main, count=75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
